{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-01-19T21:50:39.747449Z",
     "iopub.status.busy": "2025-01-19T21:50:39.747093Z",
     "iopub.status.idle": "2025-01-19T21:54:19.067377Z",
     "shell.execute_reply": "2025-01-19T21:54:19.066331Z",
     "shell.execute_reply.started": "2025-01-19T21:50:39.747418Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "!pip install pip3-autoremove\n",
    "!pip-autoremove torch torchvision torchaudio -y\n",
    "!pip install transformers bitsandbytes accelerate peft unsloth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T21:54:19.069063Z",
     "iopub.status.busy": "2025-01-19T21:54:19.068831Z",
     "iopub.status.idle": "2025-01-19T21:54:35.211946Z",
     "shell.execute_reply": "2025-01-19T21:54:35.211069Z",
     "shell.execute_reply.started": "2025-01-19T21:54:19.069044Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    BitsAndBytesConfig,\n",
    "    Gemma2ForSequenceClassification,\n",
    "    LlamaForSequenceClassification,\n",
    "    GemmaTokenizerFast,\n",
    "    Gemma2Config,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    PreTrainedTokenizerBase, \n",
    "    EvalPrediction,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorWithPadding,\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, TaskType\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "\n",
    "from unsloth import FastLanguageModel\n",
    "from accelerate import Accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T21:54:35.214145Z",
     "iopub.status.busy": "2025-01-19T21:54:35.213854Z",
     "iopub.status.idle": "2025-01-19T21:54:35.221125Z",
     "shell.execute_reply": "2025-01-19T21:54:35.220245Z",
     "shell.execute_reply.started": "2025-01-19T21:54:35.214123Z"
    }
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "\n",
    "seed_everything(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T21:54:35.222793Z",
     "iopub.status.busy": "2025-01-19T21:54:35.222462Z",
     "iopub.status.idle": "2025-01-19T21:54:35.320048Z",
     "shell.execute_reply": "2025-01-19T21:54:35.318986Z",
     "shell.execute_reply.started": "2025-01-19T21:54:35.222764Z"
    }
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    # model\n",
    "    gemma_dir: str = \"unsloth/gemma-2-9b-it-bnb-4bit\" # instruction-tuningあり\n",
    "    gemma_dir_noit: str = \"unsloth/gemma-2-9b-bnb-4bit\" # instruction-tuningなし\n",
    "    # llama_dir: str = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "    \n",
    "    # tokenizer\n",
    "    max_length: int = 1024\n",
    "\n",
    "    # lora\n",
    "    target_modules : tuple = (\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\")\n",
    "    freeze_layers: int = 0\n",
    "    lora_r: int = 16\n",
    "    lora_alpha: float = lora_r * 2\n",
    "    lora_dropout: float = 0.05\n",
    "    lora_bias: str = \"none\"\n",
    "\n",
    "    # train\n",
    "    per_device_train_batch_size: int = 8\n",
    "    gradient_accumulation_steps: int = 2\n",
    "    per_device_eval_batch_size: int = 64\n",
    "    learning_rate: float = 1e-4\n",
    "    n_epochs: int = 1\n",
    "    warmup_ratio: float = 0.1\n",
    "    eval_steps: int = 25\n",
    "    optim_type: str = \"adamw_torch_fused\"\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T21:54:35.321728Z",
     "iopub.status.busy": "2025-01-19T21:54:35.321256Z",
     "iopub.status.idle": "2025-01-19T21:54:35.365476Z",
     "shell.execute_reply": "2025-01-19T21:54:35.364603Z",
     "shell.execute_reply.started": "2025-01-19T21:54:35.321682Z"
    }
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"tmp\",\n",
    "    overwrite_output_dir=True,\n",
    "    report_to=\"none\",\n",
    "    per_device_train_batch_size=config.per_device_train_batch_size,\n",
    "    per_device_eval_batch_size=config.per_device_eval_batch_size,\n",
    "    gradient_accumulation_steps=config.gradient_accumulation_steps,\n",
    "    learning_rate=config.learning_rate,\n",
    "    num_train_epochs=config.n_epochs,\n",
    "    warmup_ratio=config.warmup_ratio,\n",
    "    logging_steps=config.eval_steps,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=config.eval_steps,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=config.eval_steps,\n",
    "    save_total_limit=2,\n",
    "    fp16=True,\n",
    "    metric_for_best_model=\"auc\",\n",
    "    greater_is_better=True,\n",
    "    optim=config.optim_type,\n",
    "    full_determinism=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T21:54:35.366798Z",
     "iopub.status.busy": "2025-01-19T21:54:35.366491Z",
     "iopub.status.idle": "2025-01-19T21:54:35.371334Z",
     "shell.execute_reply": "2025-01-19T21:54:35.370408Z",
     "shell.execute_reply.started": "2025-01-19T21:54:35.366770Z"
    }
   },
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    r=config.lora_r,\n",
    "    target_modules=config.target_modules,\n",
    "    lora_alpha=config.lora_alpha,\n",
    "    lora_dropout=config.lora_dropout,\n",
    "    bias=config.lora_bias,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T21:54:35.372578Z",
     "iopub.status.busy": "2025-01-19T21:54:35.372247Z",
     "iopub.status.idle": "2025-01-19T21:54:35.499482Z",
     "shell.execute_reply": "2025-01-19T21:54:35.498693Z",
     "shell.execute_reply.started": "2025-01-19T21:54:35.372544Z"
    }
   },
   "outputs": [],
   "source": [
    "INPUT_DIR = \"/kaggle/input/defp2024-kaggle-5\"\n",
    "\n",
    "df_train = pd.read_csv(f\"{INPUT_DIR}/train.csv\", low_memory=False)\n",
    "df_test = pd.read_csv(f\"{INPUT_DIR}/test.csv\", low_memory=False)\n",
    "print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T21:54:35.502048Z",
     "iopub.status.busy": "2025-01-19T21:54:35.501827Z",
     "iopub.status.idle": "2025-01-19T21:54:35.505763Z",
     "shell.execute_reply": "2025-01-19T21:54:35.504708Z",
     "shell.execute_reply.started": "2025-01-19T21:54:35.502029Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt = (\n",
    "    \"Is the following movie appropriate for viewing by young people?\\n\"\n",
    "    \"Title: {title}\\n\"\n",
    "    \"Description: {description}\"\n",
    ")\n",
    "\n",
    "df_train[\"text\"] = [prompt.format(\n",
    "    title=row[\"title\"],\n",
    "    description=row[\"description\"],\n",
    ") for _, row in df_train.iterrows()]\n",
    "\n",
    "df_test[\"text\"] = [prompt.format(\n",
    "    title=row[\"title\"],\n",
    "    description=row[\"description\"],\n",
    ") for _, row in df_test.iterrows()]\n",
    "\n",
    "df_train[\"labels\"] = df_train[\"rating_flag\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T21:54:35.507366Z",
     "iopub.status.busy": "2025-01-19T21:54:35.507123Z",
     "iopub.status.idle": "2025-01-19T21:54:35.519288Z",
     "shell.execute_reply": "2025-01-19T21:54:35.518539Z",
     "shell.execute_reply.started": "2025-01-19T21:54:35.507343Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize(row, tokenizer):\n",
    "    return tokenizer(row[\"text\"], padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T21:54:35.520540Z",
     "iopub.status.busy": "2025-01-19T21:54:35.520223Z",
     "iopub.status.idle": "2025-01-19T21:54:35.530800Z",
     "shell.execute_reply": "2025-01-19T21:54:35.529936Z",
     "shell.execute_reply.started": "2025-01-19T21:54:35.520510Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_model(lora_config):\n",
    "    model = Gemma2ForSequenceClassification.from_pretrained(\n",
    "        config.gemma_dir,\n",
    "        num_labels=2,\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"auto\",\n",
    "    )\n",
    "    model.config.use_cache = False\n",
    "    model = prepare_model_for_kbit_training(model)\n",
    "    model = get_peft_model(model, lora_config)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T21:54:35.531839Z",
     "iopub.status.busy": "2025-01-19T21:54:35.531596Z",
     "iopub.status.idle": "2025-01-19T21:54:35.547877Z",
     "shell.execute_reply": "2025-01-19T21:54:35.546990Z",
     "shell.execute_reply.started": "2025-01-19T21:54:35.531817Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    preds = torch.from_numpy(preds).float().softmax(-1).numpy()[:, -1]\n",
    "    auc = roc_auc_score(labels, preds)\n",
    "    return {\"auc\": auc}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データ準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(config.gemma_dir)\n",
    "tokenizer.add_eos_token = True  # We'll add <eos> at the end\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "ds = Dataset.from_pandas(df_train[[\"text\", \"labels\"]])\n",
    "ds = ds.map(tokenize, batched=True, fn_kwargs={\"tokenizer\": tokenizer})\n",
    "\n",
    "ds_test = Dataset.from_pandas(df_test[[\"text\"]])\n",
    "ds_test = ds_test.map(tokenize, batched=True, fn_kwargs={\"tokenizer\": tokenizer})\n",
    "\n",
    "ds_train, ds_valid = ds.train_test_split(test_size=0.2).values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gemma-2-9b-it-bnb-4bit + SequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T11:46:16.941511Z",
     "iopub.status.busy": "2025-01-19T11:46:16.941263Z",
     "iopub.status.idle": "2025-01-19T11:46:16.944858Z",
     "shell.execute_reply": "2025-01-19T11:46:16.944150Z",
     "shell.execute_reply.started": "2025-01-19T11:46:16.941489Z"
    }
   },
   "outputs": [],
   "source": [
    "# model  = Gemma2ForSequenceClassification.from_pretrained(\n",
    "#         config.gemma_dir,\n",
    "#         num_labels=2,\n",
    "#         torch_dtype=torch.float16,\n",
    "#         device_map=\"auto\",\n",
    "#     )\n",
    "# model.config.use_cache = False\n",
    "# model = prepare_model_for_kbit_training(model)\n",
    "# model = get_peft_model(model, lora_config)\n",
    "\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T11:46:16.945833Z",
     "iopub.status.busy": "2025-01-19T11:46:16.945578Z",
     "iopub.status.idle": "2025-01-19T11:46:17.205080Z",
     "shell.execute_reply": "2025-01-19T11:46:17.204420Z",
     "shell.execute_reply.started": "2025-01-19T11:46:16.945802Z"
    }
   },
   "outputs": [],
   "source": [
    "# trainer = Trainer(\n",
    "#         args=training_args,\n",
    "#         model=model,\n",
    "#         tokenizer=tokenizer,\n",
    "#         train_dataset=ds_train,\n",
    "#         eval_dataset=ds_valid,\n",
    "#         compute_metrics=compute_metrics,\n",
    "#         data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "#     )\n",
    "# trainer.train()\n",
    "\n",
    "# preds = trainer.predict(ds_valid).predictions\n",
    "# preds_oof_llama = torch.from_numpy(preds).float().softmax(dim=-1).numpy()[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T11:46:17.206047Z",
     "iopub.status.busy": "2025-01-19T11:46:17.205807Z",
     "iopub.status.idle": "2025-01-19T11:46:17.224356Z",
     "shell.execute_reply": "2025-01-19T11:46:17.223768Z",
     "shell.execute_reply.started": "2025-01-19T11:46:17.206027Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(roc_auc_score(ds_valid[\"labels\"], preds_oof_llama))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gemma-2-9b-bnb-4bit + SequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T11:46:17.225549Z",
     "iopub.status.busy": "2025-01-19T11:46:17.225263Z",
     "iopub.status.idle": "2025-01-19T11:49:05.109179Z",
     "shell.execute_reply": "2025-01-19T11:49:05.108510Z",
     "shell.execute_reply.started": "2025-01-19T11:46:17.225522Z"
    }
   },
   "outputs": [],
   "source": [
    "model  = Gemma2ForSequenceClassification.from_pretrained(\n",
    "        config.gemma_dir_noit,\n",
    "        num_labels=2,\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"auto\",\n",
    "    )\n",
    "model.config.use_cache = False\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T11:49:05.110286Z",
     "iopub.status.busy": "2025-01-19T11:49:05.110074Z",
     "iopub.status.idle": "2025-01-19T13:35:58.323357Z",
     "shell.execute_reply": "2025-01-19T13:35:58.322541Z",
     "shell.execute_reply.started": "2025-01-19T11:49:05.110267Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "        args=training_args,\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        train_dataset=ds_train,\n",
    "        eval_dataset=ds_valid,\n",
    "        compute_metrics=compute_metrics,\n",
    "        data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    )\n",
    "trainer.train()\n",
    "\n",
    "preds = trainer.predict(ds_valid).predictions\n",
    "preds_oof_llama = torch.from_numpy(preds).float().softmax(dim=-1).numpy()[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T13:35:58.324662Z",
     "iopub.status.busy": "2025-01-19T13:35:58.324344Z",
     "iopub.status.idle": "2025-01-19T13:35:58.339075Z",
     "shell.execute_reply": "2025-01-19T13:35:58.338285Z",
     "shell.execute_reply.started": "2025-01-19T13:35:58.324638Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(roc_auc_score(ds_valid[\"labels\"], preds_oof_llama))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = trainer.predict(ds_test).predictions\n",
    "preds_test = torch.from_numpy(preds).float().softmax(dim=-1).numpy()[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = df_test[[\"show_id\"]].copy()\n",
    "df_pred[\"pred\"] = preds_test\n",
    "df_pred.to_csv(f\"submission_late_gemma_class.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 10485141,
     "sourceId": 90350,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30822,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
