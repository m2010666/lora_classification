{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":90350,"databundleVersionId":10485141,"sourceType":"competition"}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pip3-autoremove\n!pip-autoremove torch torchvision torchaudio -y\n!pip install transformers bitsandbytes accelerate peft unsloth","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T21:50:39.747093Z","iopub.execute_input":"2025-01-19T21:50:39.747449Z","iopub.status.idle":"2025-01-19T21:54:19.067377Z","shell.execute_reply.started":"2025-01-19T21:50:39.747418Z","shell.execute_reply":"2025-01-19T21:54:19.066331Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport copy\nimport random\nfrom dataclasses import dataclass\n\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom datasets import Dataset\nfrom transformers import (\n    BitsAndBytesConfig,\n    Gemma2ForSequenceClassification,\n    LlamaForSequenceClassification,\n    GemmaTokenizerFast,\n    Gemma2Config,\n    AutoTokenizer,\n    AutoModelForSequenceClassification,\n    PreTrainedTokenizerBase, \n    EvalPrediction,\n    Trainer,\n    TrainingArguments,\n    DataCollatorWithPadding,\n)\nfrom peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, TaskType\nfrom sklearn.metrics import log_loss, roc_auc_score\n\nfrom unsloth import FastLanguageModel\nfrom accelerate import Accelerator","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T21:54:19.068831Z","iopub.execute_input":"2025-01-19T21:54:19.069063Z","iopub.status.idle":"2025-01-19T21:54:35.211946Z","shell.execute_reply.started":"2025-01-19T21:54:19.069044Z","shell.execute_reply":"2025-01-19T21:54:35.211069Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def seed_everything(seed):\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    torch.manual_seed(seed)\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.use_deterministic_algorithms(True)\n\nseed_everything(0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T21:54:35.213854Z","iopub.execute_input":"2025-01-19T21:54:35.214145Z","iopub.status.idle":"2025-01-19T21:54:35.221125Z","shell.execute_reply.started":"2025-01-19T21:54:35.214123Z","shell.execute_reply":"2025-01-19T21:54:35.220245Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"@dataclass\nclass Config:\n    # model\n    gemma_dir: str = \"unsloth/gemma-2-9b-it-bnb-4bit\" # instruction-tuningあり\n    gemma_dir_noit: str = \"unsloth/gemma-2-9b-bnb-4bit\" # instruction-tuningなし\n    # llama_dir: str = \"meta-llama/Llama-3.2-3B-Instruct\"\n    \n    # tokenizer\n    max_length: int = 1024\n\n    # lora\n    target_modules : tuple = (\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\")\n    freeze_layers: int = 0\n    lora_r: int = 16\n    lora_alpha: float = lora_r * 2\n    lora_dropout: float = 0.05\n    lora_bias: str = \"none\"\n\n    # train\n    per_device_train_batch_size: int = 8\n    gradient_accumulation_steps: int = 2\n    per_device_eval_batch_size: int = 64\n    learning_rate: float = 1e-4\n    n_epochs: int = 1\n    warmup_ratio: float = 0.1\n    eval_steps: int = 25\n    optim_type: str = \"adamw_torch_fused\"\n\nconfig = Config()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T21:54:35.222462Z","iopub.execute_input":"2025-01-19T21:54:35.222793Z","iopub.status.idle":"2025-01-19T21:54:35.320048Z","shell.execute_reply.started":"2025-01-19T21:54:35.222764Z","shell.execute_reply":"2025-01-19T21:54:35.318986Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"tmp\",\n    overwrite_output_dir=True,\n    report_to=\"none\",\n    per_device_train_batch_size=config.per_device_train_batch_size,\n    per_device_eval_batch_size=config.per_device_eval_batch_size,\n    gradient_accumulation_steps=config.gradient_accumulation_steps,\n    learning_rate=config.learning_rate,\n    num_train_epochs=config.n_epochs,\n    warmup_ratio=config.warmup_ratio,\n    logging_steps=config.eval_steps,\n    eval_strategy=\"steps\",\n    eval_steps=config.eval_steps,\n    save_strategy=\"steps\",\n    save_steps=config.eval_steps,\n    save_total_limit=2,\n    fp16=True,\n    metric_for_best_model=\"auc\",\n    greater_is_better=True,\n    optim=config.optim_type,\n    full_determinism=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T21:54:35.321256Z","iopub.execute_input":"2025-01-19T21:54:35.321728Z","iopub.status.idle":"2025-01-19T21:54:35.365476Z","shell.execute_reply.started":"2025-01-19T21:54:35.321682Z","shell.execute_reply":"2025-01-19T21:54:35.364603Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"lora_config = LoraConfig(\n    task_type=TaskType.SEQ_CLS,\n    r=config.lora_r,\n    target_modules=config.target_modules,\n    lora_alpha=config.lora_alpha,\n    lora_dropout=config.lora_dropout,\n    bias=config.lora_bias,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T21:54:35.366491Z","iopub.execute_input":"2025-01-19T21:54:35.366798Z","iopub.status.idle":"2025-01-19T21:54:35.371334Z","shell.execute_reply.started":"2025-01-19T21:54:35.366770Z","shell.execute_reply":"2025-01-19T21:54:35.370408Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"INPUT_DIR = \"/kaggle/input/defp2024-kaggle-5\"\n\ndf_train = pd.read_csv(f\"{INPUT_DIR}/train.csv\", low_memory=False)\ndf_test = pd.read_csv(f\"{INPUT_DIR}/test.csv\", low_memory=False)\nprint(df_train.shape, df_test.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T21:54:35.372247Z","iopub.execute_input":"2025-01-19T21:54:35.372578Z","iopub.status.idle":"2025-01-19T21:54:35.499482Z","shell.execute_reply.started":"2025-01-19T21:54:35.372544Z","shell.execute_reply":"2025-01-19T21:54:35.498693Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## SequenceClassification","metadata":{}},{"cell_type":"code","source":"prompt = (\n    \"Is the following movie appropriate for viewing by young people?\\n\"\n    \"Title: {title}\\n\"\n    \"Description: {description}\"\n)\n\ndf_train[\"text\"] = [prompt.format(\n    title=row[\"title\"],\n    description=row[\"description\"],\n) for _, row in df_train.iterrows()]\n\ndf_test[\"text\"] = [prompt.format(\n    title=row[\"title\"],\n    description=row[\"description\"],\n) for _, row in df_test.iterrows()]\n\ndf_train[\"labels\"] = df_train[\"rating_flag\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T21:54:35.501827Z","iopub.execute_input":"2025-01-19T21:54:35.502048Z","iopub.status.idle":"2025-01-19T21:54:35.505763Z","shell.execute_reply.started":"2025-01-19T21:54:35.502029Z","shell.execute_reply":"2025-01-19T21:54:35.504708Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def tokenize(row, tokenizer):\n    return tokenizer(row[\"text\"], padding=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T21:54:35.507123Z","iopub.execute_input":"2025-01-19T21:54:35.507366Z","iopub.status.idle":"2025-01-19T21:54:35.519288Z","shell.execute_reply.started":"2025-01-19T21:54:35.507343Z","shell.execute_reply":"2025-01-19T21:54:35.518539Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def prepare_model(lora_config):\n    model = Gemma2ForSequenceClassification.from_pretrained(\n        config.gemma_dir,\n        num_labels=2,\n        torch_dtype=torch.float16,\n        device_map=\"auto\",\n    )\n    model.config.use_cache = False\n    model = prepare_model_for_kbit_training(model)\n    model = get_peft_model(model, lora_config)\n    \n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T21:54:35.520223Z","iopub.execute_input":"2025-01-19T21:54:35.520540Z","iopub.status.idle":"2025-01-19T21:54:35.530800Z","shell.execute_reply.started":"2025-01-19T21:54:35.520510Z","shell.execute_reply":"2025-01-19T21:54:35.529936Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def compute_metrics(eval_preds):\n    preds, labels = eval_preds\n    preds = torch.from_numpy(preds).float().softmax(-1).numpy()[:, -1]\n    auc = roc_auc_score(labels, preds)\n    return {\"auc\": auc}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T21:54:35.531596Z","iopub.execute_input":"2025-01-19T21:54:35.531839Z","iopub.status.idle":"2025-01-19T21:54:35.547877Z","shell.execute_reply.started":"2025-01-19T21:54:35.531817Z","shell.execute_reply":"2025-01-19T21:54:35.546990Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## データ準備","metadata":{}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(config.gemma_dir)\ntokenizer.add_eos_token = True  # We'll add <eos> at the end\ntokenizer.padding_side = \"right\"\n\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n\nds = Dataset.from_pandas(df_train[[\"text\", \"labels\"]])\nds = ds.map(tokenize, batched=True, fn_kwargs={\"tokenizer\": tokenizer})\n\nds_test = Dataset.from_pandas(df_test[[\"text\"]])\nds_test = ds_test.map(tokenize, batched=True, fn_kwargs={\"tokenizer\": tokenizer})\n\nds_train, ds_valid = ds.train_test_split(test_size=0.2).values()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## gemma-2-9b-it-bnb-4bit + SequenceClassification","metadata":{}},{"cell_type":"code","source":"# model  = Gemma2ForSequenceClassification.from_pretrained(\n#         config.gemma_dir,\n#         num_labels=2,\n#         torch_dtype=torch.float16,\n#         device_map=\"auto\",\n#     )\n# model.config.use_cache = False\n# model = prepare_model_for_kbit_training(model)\n# model = get_peft_model(model, lora_config)\n\n# model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T11:46:16.941263Z","iopub.execute_input":"2025-01-19T11:46:16.941511Z","iopub.status.idle":"2025-01-19T11:46:16.944858Z","shell.execute_reply.started":"2025-01-19T11:46:16.941489Z","shell.execute_reply":"2025-01-19T11:46:16.944150Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# trainer = Trainer(\n#         args=training_args,\n#         model=model,\n#         tokenizer=tokenizer,\n#         train_dataset=ds_train,\n#         eval_dataset=ds_valid,\n#         compute_metrics=compute_metrics,\n#         data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n#     )\n# trainer.train()\n\n# preds = trainer.predict(ds_valid).predictions\n# preds_oof_llama = torch.from_numpy(preds).float().softmax(dim=-1).numpy()[:, -1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T11:46:16.945578Z","iopub.execute_input":"2025-01-19T11:46:16.945833Z","iopub.status.idle":"2025-01-19T11:46:17.205080Z","shell.execute_reply.started":"2025-01-19T11:46:16.945802Z","shell.execute_reply":"2025-01-19T11:46:17.204420Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# print(roc_auc_score(ds_valid[\"labels\"], preds_oof_llama))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T11:46:17.205807Z","iopub.execute_input":"2025-01-19T11:46:17.206047Z","iopub.status.idle":"2025-01-19T11:46:17.224356Z","shell.execute_reply.started":"2025-01-19T11:46:17.206027Z","shell.execute_reply":"2025-01-19T11:46:17.223768Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## gemma-2-9b-bnb-4bit + SequenceClassification","metadata":{}},{"cell_type":"code","source":"model  = Gemma2ForSequenceClassification.from_pretrained(\n        config.gemma_dir_noit,\n        num_labels=2,\n        torch_dtype=torch.float16,\n        device_map=\"auto\",\n    )\nmodel.config.use_cache = False\nmodel = prepare_model_for_kbit_training(model)\nmodel = get_peft_model(model, lora_config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T11:46:17.225263Z","iopub.execute_input":"2025-01-19T11:46:17.225549Z","iopub.status.idle":"2025-01-19T11:49:05.109179Z","shell.execute_reply.started":"2025-01-19T11:46:17.225522Z","shell.execute_reply":"2025-01-19T11:49:05.108510Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer = Trainer(\n        args=training_args,\n        model=model,\n        tokenizer=tokenizer,\n        train_dataset=ds_train,\n        eval_dataset=ds_valid,\n        compute_metrics=compute_metrics,\n        data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n    )\ntrainer.train()\n\npreds = trainer.predict(ds_valid).predictions\npreds_oof_llama = torch.from_numpy(preds).float().softmax(dim=-1).numpy()[:, -1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T11:49:05.110074Z","iopub.execute_input":"2025-01-19T11:49:05.110286Z","iopub.status.idle":"2025-01-19T13:35:58.323357Z","shell.execute_reply.started":"2025-01-19T11:49:05.110267Z","shell.execute_reply":"2025-01-19T13:35:58.322541Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# print(roc_auc_score(ds_valid[\"labels\"], preds_oof_llama))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T13:35:58.324344Z","iopub.execute_input":"2025-01-19T13:35:58.324662Z","iopub.status.idle":"2025-01-19T13:35:58.339075Z","shell.execute_reply.started":"2025-01-19T13:35:58.324638Z","shell.execute_reply":"2025-01-19T13:35:58.338285Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Test","metadata":{}},{"cell_type":"code","source":"preds = trainer.predict(ds_test).predictions\npreds_test = torch.from_numpy(preds).float().softmax(dim=-1).numpy()[:, -1]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_pred = df_test[[\"show_id\"]].copy()\ndf_pred[\"pred\"] = preds_test\ndf_pred.to_csv(f\"submission_late_gemma_class.csv\", index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}